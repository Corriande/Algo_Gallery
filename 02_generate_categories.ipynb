{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9590abe0",
   "metadata": {},
   "source": [
    "# 02_generate_categories\n",
    "\n",
    "## Notebook 2/4\n",
    "\n",
    "## Gabriel del Valle\n",
    "## 10/08/24\n",
    "## NYC DATA SCIENCE ACADEMY\n",
    "\n",
    "\n",
    "## The purpose of this project is to create a simplified context to apply content recommendation techniques in an interactive Shiny app.\n",
    "\n",
    "\n",
    "### Try out the full interactive app! Read the Home page for project details and instructions\n",
    "\n",
    "https://gabrielxdelvalle.shinyapps.io/algo_gallery/\n",
    "\n",
    "### Read the full project details on the blog post:\n",
    "\n",
    "https://nycdatascience.com/blog/student-works/clustering-artworks-by-ai-quantified-visual-qualities-content-recommendation-app/\n",
    "\n",
    "### For any questions or inquieries about this project please feel free to reach out on Linkedin: \n",
    "\n",
    "www.linkedin.com/in/gabriel-del-valle-147616152\n",
    "\n",
    "\n",
    "## This second notebook is used to apply OpenAI's CLIP image classficaiton tool to generate image scores fore each artwork, and store them in a dataframe along with the art's descriptive inforamtion (such as title, date, etc) and an image link\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Notebook Structure \n",
    "\n",
    "### 1. Load CLIP model and processor\n",
    "\n",
    "### 2. Generate image scores for a set of categories, using function clip_scores( )\n",
    "\n",
    "#### clip_scores( ) takes as inputs a list of image paths (to the locally stored image) and a list of categories (type string) and returns a dataframe with each category as a column, each image as a row, and the image scores as values\n",
    "\n",
    "- This could also be made to work with image links using the io library\n",
    "\n",
    "\n",
    "### 3. For comparison purposes, generate multiple sets of image scores with different combinations of categories using generate_clips( )\n",
    "\n",
    "#### generate_clips takes as input a list of image paths, a list of strong categories and a list of weak categories. First it will generate scores for just the strong categories and label the dataframe \"benchmark\". Then it will generate each combination of a single weak category + all strong categories, and store the data in a dataframe labeled based on the weak quality. \n",
    "\n",
    "- the datatype output by generate_clips is a dictionary of dataframes. This can be saved using a pickle file, or one can loop through each dict value and export the individual dataframes as csv\n",
    "\n",
    "### 4. To add image scores directly to the dataframe containing art details and image paths, generate_clips_gallery( ) takes as inputs a dataframe and a list of categories, and returns a new dataframe with the image scores as new columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f776a519",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrieldelvalle/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from transformers import pipeline\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edfc6ee",
   "metadata": {},
   "source": [
    "## Load the model and processor for CLIP:\n",
    "\n",
    "- The processor’s job is to prepare the data (image and text inputs) into the format required by the model. This includes resizing, normalizing, and converting images into tensor form and tokenizing the text prompts.\n",
    "\n",
    "- CLIPProcessor automates several pre-processing steps to ensure consistency with the model’s training, handling aspects like image size normalization and text tokenization.\n",
    "\n",
    "- Without the processor, one would need to manually implement these pre-processing steps to match the CLIP model’s expectations. For example, if the image dimensions or pixel values are not standardized, it would likely impact the model's performance and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c16a9d2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db6048801fe42e084f7e8d085bed312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd3c50c4c4541788ba1ab333adba18c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrieldelvalle/anaconda3/lib/python3.11/site-packages/transformers/modeling_utils.py:479: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ffb3e8ed7f42dc818217113d350a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)rocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "907725a837b54d2d9488dafa8d4a13c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7009da2dba4862bfdf3a464fd1572a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/862k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2fdf7c15482474f9fa4e4862da1a66e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bdfe00399f043a2863474f35c164621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/2.22M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa739bde12a41f9bcbaa2495ceeec93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "488810bda8574beebb0acee8ae9698fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load CLIP model and processor for handling both image and text\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\", force_download=True)\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\", force_download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b95cea",
   "metadata": {},
   "source": [
    "## Process images with CLIP:\n",
    "\n",
    "### If you have a CUDA-compatible GPU, transferring data and computations to the GPU can significantly speed up processing time. \n",
    "### Without this step, the code will run on the CPU, which may be much slower, especially for large batches of images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e6ce8f",
   "metadata": {},
   "source": [
    "\n",
    "### Logits are the raw image scores for each category and are independent by default\n",
    "### Applying the softmax is what converts these values into probabilities, aka dependent, aka sum to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3be77da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your generate_clip_scores function to generate CLIP scores for each image\n",
    "def clip_scores(images, categories):\n",
    "    all_scores = []\n",
    "    \n",
    "    for ex_image in images:\n",
    "        image = Image.open(ex_image)\n",
    "        \n",
    "        # Process the image and candidate labels\n",
    "        inputs = processor(text=categories, images=image, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "        # Move the model to the GPU if available\n",
    "        \n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        model.to(device)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        # Get the logits from the model\n",
    "        with torch.no_grad():\n",
    "            logits_per_image = model(**inputs).logits_per_image  # This gives the similarity score between the image and each label\n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probs = logits_per_image.softmax(dim=-1)\n",
    "\n",
    "        # Collect scores for the image\n",
    "        scores = [prob.item() for prob in probs[0]]\n",
    "        all_scores.append(scores)\n",
    "    \n",
    "    # Return as a pandas DataFrame\n",
    "    return pd.DataFrame(all_scores, columns=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e9afbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate different combinations of strong and weak qualities by generating CLIP scores\n",
    "def generate_clips(images, strong_qualities, weak_qualities):\n",
    "    # Initialize a dictionary to store the results\n",
    "    results = {}\n",
    "\n",
    "    # Generate and store benchmark scores for strong qualities alone\n",
    "    print(\"Generating CLIP scores with only strong qualities...\")\n",
    "    data_strong = clip_scores(images, strong_qualities)\n",
    "    results[\"benchmark\"] = data_strong\n",
    "    \n",
    "    # Now test adding one weak quality at a time\n",
    "    for weak_quality in weak_qualities:\n",
    "        print(f\"\\nGenerating CLIP scores for strong qualities + weak quality: {weak_quality}\")\n",
    "        \n",
    "        # Add the current weak quality to the list of strong qualities\n",
    "        categories_to_test = strong_qualities + [weak_quality]\n",
    "        \n",
    "        # Generate the CLIP scores for the updated set of categories\n",
    "        data = clip_scores(images, categories_to_test)\n",
    "        \n",
    "        # Store the data with the weak quality as the key\n",
    "        results[weak_quality] = data\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7d5a285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "974"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modern_gallery = pd.read_csv(\"modern_gallery.csv\")\n",
    "len(modern_gallery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "850978d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = \"modern_gallery_images2/\" + modern_gallery['Image_path'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "04d320c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_qualities = [\n",
    "    \n",
    "    'Highly_Detailed',\n",
    "    'Human_Subject',\n",
    "    'Landscape',\n",
    "    'Abstract',\n",
    "    'Ornamental_Pattern',\n",
    "    'Animal_Subject',\n",
    "    'Architecture_Subject',\n",
    "    'Many_Colors'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42c66d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "weak_qualities = [\n",
    "    \n",
    "    'Color_Complexity',\n",
    "    'Color_Contrast',\n",
    "    'Religious',\n",
    "    'Plant_Subject',\n",
    "    'Flower_Subject',\n",
    "    'Many_Colors',\n",
    "    'Minimalist',\n",
    "    \n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5f9b86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1d86a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating CLIP scores with only strong qualities...\n",
      "\n",
      "Generating CLIP scores for strong qualities + weak quality: Color_Complexity\n",
      "\n",
      "Generating CLIP scores for strong qualities + weak quality: Color_Contrast\n",
      "\n",
      "Generating CLIP scores for strong qualities + weak quality: Religious\n",
      "\n",
      "Generating CLIP scores for strong qualities + weak quality: Plant_Subject\n",
      "\n",
      "Generating CLIP scores for strong qualities + weak quality: Flower_Subject\n",
      "\n",
      "Generating CLIP scores for strong qualities + weak quality: Many_Colors\n",
      "\n",
      "Generating CLIP scores for strong qualities + weak quality: Minimalist\n"
     ]
    }
   ],
   "source": [
    "trial = generate_clips(image_paths, strong_qualities, weak_qualities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04eee505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'benchmark':      Impressionist  Highly_Detailed  Human_Subject  Landscape  Abstract  \\\n",
       " 0         0.039867         0.004297       0.025354   0.103506  0.810500   \n",
       " 1         0.223959         0.021343       0.269724   0.438612  0.013003   \n",
       " 2         0.025285         0.032247       0.033692   0.118063  0.634435   \n",
       " 3         0.027713         0.094089       0.117573   0.447257  0.047408   \n",
       " 4         0.011274         0.042059       0.166050   0.200608  0.358758   \n",
       " ..             ...              ...            ...        ...       ...   \n",
       " 969       0.168745         0.070212       0.352094   0.167473  0.080242   \n",
       " 970       0.244714         0.028867       0.043010   0.445560  0.134066   \n",
       " 971       0.359046         0.030887       0.146380   0.142607  0.253359   \n",
       " 972       0.137914         0.015053       0.079349   0.334707  0.066345   \n",
       " 973       0.011893         0.135747       0.157344   0.088316  0.129734   \n",
       " \n",
       "      Ornamental_Pattern  Highly_Detailed  Animal_Subject  \n",
       " 0              0.006760         0.004297        0.005419  \n",
       " 1              0.001570         0.021343        0.010445  \n",
       " 2              0.111027         0.032247        0.013005  \n",
       " 3              0.044176         0.094089        0.127695  \n",
       " 4              0.036627         0.042059        0.142563  \n",
       " ..                  ...              ...             ...  \n",
       " 969            0.020822         0.070212        0.070200  \n",
       " 970            0.030049         0.028867        0.044866  \n",
       " 971            0.003999         0.030887        0.032835  \n",
       " 972            0.016295         0.015053        0.335283  \n",
       " 973            0.188872         0.135747        0.152347  \n",
       " \n",
       " [974 rows x 8 columns],\n",
       " 'Color_Complexity':      Impressionist  Highly_Detailed  Human_Subject  Landscape  Abstract  \\\n",
       " 0         0.032943         0.003551       0.020951   0.085528  0.669726   \n",
       " 1         0.222518         0.021206       0.267989   0.435790  0.012920   \n",
       " 2         0.024487         0.031228       0.032627   0.114333  0.614393   \n",
       " 3         0.021942         0.074495       0.093089   0.354117  0.037536   \n",
       " 4         0.010504         0.039185       0.154705   0.186901  0.334244   \n",
       " ..             ...              ...            ...        ...       ...   \n",
       " 969       0.165913         0.069034       0.346186   0.164663  0.078895   \n",
       " 970       0.239022         0.028196       0.042009   0.435196  0.130948   \n",
       " 971       0.300467         0.025848       0.122498   0.119340  0.212023   \n",
       " 972       0.135142         0.014751       0.077754   0.327980  0.065012   \n",
       " 973       0.011070         0.126356       0.146459   0.082206  0.120759   \n",
       " \n",
       "      Ornamental_Pattern  Highly_Detailed  Animal_Subject  Color_Complexity  \n",
       " 0              0.005586         0.003551        0.004478          0.173688  \n",
       " 1              0.001560         0.021206        0.010378          0.006433  \n",
       " 2              0.107519         0.031228        0.012594          0.031591  \n",
       " 3              0.034976         0.074495        0.101104          0.208246  \n",
       " 4              0.034125         0.039185        0.132822          0.068330  \n",
       " ..                  ...              ...             ...               ...  \n",
       " 969            0.020472         0.069034        0.069022          0.016781  \n",
       " 970            0.029350         0.028196        0.043822          0.023260  \n",
       " 971            0.003346         0.025848        0.027478          0.163153  \n",
       " 972            0.015968         0.014751        0.328547          0.020097  \n",
       " 973            0.175805         0.126356        0.141808          0.069179  \n",
       " \n",
       " [974 rows x 9 columns],\n",
       " 'Color_Contrast':      Impressionist  Highly_Detailed  Human_Subject  Landscape  Abstract  \\\n",
       " 0         0.031397         0.003384       0.019968   0.081515  0.638305   \n",
       " 1         0.220564         0.021020       0.265636   0.431964  0.012806   \n",
       " 2         0.024872         0.031719       0.033141   0.116131  0.624057   \n",
       " 3         0.023793         0.080780       0.100943   0.383993  0.040702   \n",
       " 4         0.010574         0.039445       0.155732   0.188142  0.336464   \n",
       " ..             ...              ...            ...        ...       ...   \n",
       " 969       0.155173         0.064565       0.323775   0.154003  0.073788   \n",
       " 970       0.240644         0.028387       0.042295   0.438150  0.131836   \n",
       " 971       0.336664         0.028962       0.137255   0.133717  0.237565   \n",
       " 972       0.128538         0.014030       0.073954   0.311953  0.061835   \n",
       " 973       0.009489         0.108304       0.125535   0.070462  0.103507   \n",
       " \n",
       "      Ornamental_Pattern  Highly_Detailed  Animal_Subject  Color_Contrast  \n",
       " 0              0.005324         0.003384        0.004268        0.212456  \n",
       " 1              0.001546         0.021020        0.010287        0.015158  \n",
       " 2              0.109211         0.031719        0.012793        0.016358  \n",
       " 3              0.037927         0.080780        0.109634        0.141446  \n",
       " 4              0.034351         0.039445        0.133704        0.062144  \n",
       " ..                  ...              ...             ...             ...  \n",
       " 969            0.019147         0.064565        0.064554        0.080432  \n",
       " 970            0.029549         0.028387        0.044120        0.016632  \n",
       " 971            0.003750         0.028962        0.030789        0.062339  \n",
       " 972            0.015188         0.014030        0.312493        0.067979  \n",
       " 973            0.150688         0.108304        0.121548        0.202162  \n",
       " \n",
       " [974 rows x 9 columns],\n",
       " 'Religious':      Impressionist  Highly_Detailed  Human_Subject  Landscape  Abstract  \\\n",
       " 0         0.039830         0.004293       0.025331   0.103409  0.809744   \n",
       " 1         0.221190         0.021079       0.266390   0.433190  0.012843   \n",
       " 2         0.025280         0.032239       0.033684   0.118036  0.634290   \n",
       " 3         0.027639         0.093838       0.117260   0.446063  0.047282   \n",
       " 4         0.011218         0.041850       0.165227   0.199613  0.356979   \n",
       " ..             ...              ...            ...        ...       ...   \n",
       " 969       0.166472         0.069266       0.347351   0.165217  0.079161   \n",
       " 970       0.243062         0.028672       0.042720   0.442553  0.133161   \n",
       " 971       0.355999         0.030625       0.145138   0.141396  0.251208   \n",
       " 972       0.136248         0.014871       0.078391   0.330665  0.065544   \n",
       " 973       0.011835         0.135083       0.156574   0.087884  0.129099   \n",
       " \n",
       "      Ornamental_Pattern  Highly_Detailed  Animal_Subject  Religious  \n",
       " 0              0.006753         0.004293        0.005414   0.000933  \n",
       " 1              0.001550         0.021079        0.010316   0.012363  \n",
       " 2              0.111001         0.032239        0.013002   0.000229  \n",
       " 3              0.044058         0.093838        0.127355   0.002668  \n",
       " 4              0.036446         0.041850        0.141857   0.004959  \n",
       " ..                  ...              ...             ...        ...  \n",
       " 969            0.020541         0.069266        0.069254   0.013472  \n",
       " 970            0.029846         0.028672        0.044563   0.006750  \n",
       " 971            0.003965         0.030625        0.032557   0.008487  \n",
       " 972            0.016099         0.014871        0.331237   0.012073  \n",
       " 973            0.187947         0.135083        0.151601   0.004895  \n",
       " \n",
       " [974 rows x 9 columns],\n",
       " 'Plant_Subject':      Impressionist  Highly_Detailed  Human_Subject  Landscape  Abstract  \\\n",
       " 0         0.038868         0.004189       0.024719   0.100911  0.790182   \n",
       " 1         0.223399         0.021290       0.269051   0.437516  0.012971   \n",
       " 2         0.024686         0.031482       0.032893   0.115264  0.619397   \n",
       " 3         0.025875         0.087848       0.109775   0.417589  0.044264   \n",
       " 4         0.010885         0.040608       0.160320   0.193685  0.346377   \n",
       " ..             ...              ...            ...        ...       ...   \n",
       " 969       0.162243         0.067507       0.338527   0.161020  0.077150   \n",
       " 970       0.160232         0.018901       0.028162   0.291739  0.087783   \n",
       " 971       0.352961         0.030364       0.143899   0.140190  0.249065   \n",
       " 972       0.135543         0.014794       0.077985   0.328953  0.065205   \n",
       " 973       0.010822         0.123523       0.143174   0.080363  0.118051   \n",
       " \n",
       "      Ornamental_Pattern  Highly_Detailed  Animal_Subject  Plant_Subject  \n",
       " 0              0.006590         0.004189        0.005283       0.025069  \n",
       " 1              0.001566         0.021290        0.010419       0.002499  \n",
       " 2              0.108395         0.031482        0.012697       0.023703  \n",
       " 3              0.041246         0.087848        0.119226       0.066331  \n",
       " 4              0.035363         0.040608        0.137644       0.034510  \n",
       " ..                  ...              ...             ...            ...  \n",
       " 969            0.020019         0.067507        0.067495       0.038533  \n",
       " 970            0.019675         0.018901        0.029377       0.345230  \n",
       " 971            0.003931         0.030364        0.032279       0.016946  \n",
       " 972            0.016015         0.014794        0.329522       0.017190  \n",
       " 973            0.171862         0.123523        0.138627       0.090055  \n",
       " \n",
       " [974 rows x 9 columns],\n",
       " 'Flower_Subject':      Impressionist  Highly_Detailed  Human_Subject  Landscape  Abstract  \\\n",
       " 0         0.039664         0.004275       0.025225   0.102978  0.806365   \n",
       " 1         0.223463         0.021296       0.269128   0.437642  0.012975   \n",
       " 2         0.025159         0.032085       0.033523   0.117471  0.631254   \n",
       " 3         0.027508         0.093393       0.116704   0.443948  0.047057   \n",
       " 4         0.011192         0.041751       0.164834   0.199139  0.356130   \n",
       " ..             ...              ...            ...        ...       ...   \n",
       " 969       0.166352         0.069216       0.347101   0.165098  0.079104   \n",
       " 970       0.139487         0.016454       0.024516   0.253969  0.076418   \n",
       " 971       0.349927         0.030103       0.142662   0.138985  0.246924   \n",
       " 972       0.136996         0.014953       0.078821   0.332481  0.065904   \n",
       " 973       0.011625         0.132691       0.153801   0.086327  0.126813   \n",
       " \n",
       "      Ornamental_Pattern  Highly_Detailed  Animal_Subject  Flower_Subject  \n",
       " 0              0.006725         0.004275        0.005392        0.005102  \n",
       " 1              0.001566         0.021296        0.010422        0.002213  \n",
       " 2              0.110470         0.032085        0.012940        0.005014  \n",
       " 3              0.043849         0.093393        0.126751        0.007397  \n",
       " 4              0.036359         0.041751        0.141519        0.007325  \n",
       " ..                  ...              ...             ...             ...  \n",
       " 969            0.020526         0.069216        0.069205        0.014182  \n",
       " 970            0.017128         0.016454        0.025574        0.430001  \n",
       " 971            0.003897         0.030103        0.032002        0.025398  \n",
       " 972            0.016187         0.014953        0.333056        0.006650  \n",
       " 973            0.184618         0.132691        0.148916        0.022519  \n",
       " \n",
       " [974 rows x 9 columns],\n",
       " 'Many_Colors':      Impressionist  Highly_Detailed  Human_Subject  Landscape  Abstract  \\\n",
       " 0         0.038238         0.004121       0.024318   0.099276  0.777376   \n",
       " 1         0.223045         0.021256       0.268624   0.436823  0.012950   \n",
       " 2         0.025258         0.032212       0.033655   0.117936  0.633754   \n",
       " 3         0.026225         0.089036       0.111259   0.423236  0.044862   \n",
       " 4         0.011229         0.041891       0.165389   0.199809  0.357328   \n",
       " ..             ...              ...            ...        ...       ...   \n",
       " 969       0.168427         0.070080       0.351431   0.167157  0.080090   \n",
       " 970       0.243634         0.028740       0.042820   0.443593  0.133474   \n",
       " 971       0.342491         0.029463       0.139631   0.136031  0.241677   \n",
       " 972       0.136074         0.014852       0.078290   0.330241  0.065460   \n",
       " 973       0.011628         0.132720       0.153835   0.086346  0.126841   \n",
       " \n",
       "      Ornamental_Pattern  Highly_Detailed  Animal_Subject  Many_Colors  \n",
       " 0              0.006483         0.004121        0.005198     0.040868  \n",
       " 1              0.001563         0.021256        0.010402     0.004079  \n",
       " 2              0.110908         0.032212        0.012991     0.001073  \n",
       " 3              0.041803         0.089036        0.120838     0.053705  \n",
       " 4              0.036481         0.041891        0.141995     0.003985  \n",
       " ..                  ...              ...             ...          ...  \n",
       " 969            0.020782         0.070080        0.070068     0.001884  \n",
       " 970            0.029916         0.028740        0.044668     0.004416  \n",
       " 971            0.003815         0.029463        0.031322     0.046108  \n",
       " 972            0.016078         0.014852        0.330812     0.013341  \n",
       " 973            0.184659         0.132720        0.148949     0.022303  \n",
       " \n",
       " [974 rows x 9 columns],\n",
       " 'Minimalist':      Impressionist  Highly_Detailed  Human_Subject  Landscape  Abstract  \\\n",
       " 0         0.038725         0.004174       0.024628   0.100540  0.787278   \n",
       " 1         0.223802         0.021328       0.269536   0.438305  0.012994   \n",
       " 2         0.025235         0.032182       0.033624   0.117826  0.633164   \n",
       " 3         0.027694         0.094024       0.117492   0.446948  0.047375   \n",
       " 4         0.011166         0.041656       0.164459   0.198685  0.355318   \n",
       " ..             ...              ...            ...        ...       ...   \n",
       " 969       0.164102         0.068280       0.342406   0.162864  0.078034   \n",
       " 970       0.244612         0.028855       0.042992   0.445373  0.134010   \n",
       " 971       0.358202         0.030815       0.146036   0.142271  0.252763   \n",
       " 972       0.137718         0.015032       0.079236   0.334232  0.066251   \n",
       " 973       0.009962         0.113709       0.131799   0.073978  0.108672   \n",
       " \n",
       "      Ornamental_Pattern  Highly_Detailed  Animal_Subject  Minimalist  \n",
       " 0              0.006566         0.004174        0.005264    0.028651  \n",
       " 1              0.001569         0.021328        0.010438    0.000701  \n",
       " 2              0.110804         0.032182        0.012979    0.002003  \n",
       " 3              0.044145         0.094024        0.127608    0.000689  \n",
       " 4              0.036276         0.041656        0.141197    0.009588  \n",
       " ..                  ...              ...             ...         ...  \n",
       " 969            0.020249         0.068280        0.068268    0.027518  \n",
       " 970            0.030036         0.028855        0.044847    0.000419  \n",
       " 971            0.003990         0.030815        0.032759    0.002351  \n",
       " 972            0.016272         0.015032        0.334810    0.001416  \n",
       " 973            0.158208         0.113709        0.127613    0.162351  \n",
       " \n",
       " [974 rows x 9 columns]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e826d0c",
   "metadata": {},
   "source": [
    "### Example saving dict of dataframes to pickle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14edfeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Export the entire 'results' dictionary as a pickle file\n",
    "with open('clip_scores_results.pkl', 'wb') as f:\n",
    "    pickle.dump(trial, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25fe3e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the results from the pickle file\n",
    "with open('clip_scores_results.pkl', 'rb') as f:\n",
    "    trial = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92651a15",
   "metadata": {},
   "source": [
    "### Example saving each dataframe in the dict to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f41d1143",
   "metadata": {},
   "outputs": [],
   "source": [
    "for quality, df in trial.items():\n",
    "    df.to_csv(f\"{quality}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5bfb54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Impressionist</th>\n",
       "      <th>Highly_Detailed</th>\n",
       "      <th>Human_Subject</th>\n",
       "      <th>Landscape</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Ornamental_Pattern</th>\n",
       "      <th>Animal_Subject</th>\n",
       "      <th>Architecture_Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035234</td>\n",
       "      <td>0.003798</td>\n",
       "      <td>0.022408</td>\n",
       "      <td>0.091478</td>\n",
       "      <td>0.716316</td>\n",
       "      <td>0.005974</td>\n",
       "      <td>0.004790</td>\n",
       "      <td>0.120002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.209611</td>\n",
       "      <td>0.019976</td>\n",
       "      <td>0.252444</td>\n",
       "      <td>0.410513</td>\n",
       "      <td>0.012170</td>\n",
       "      <td>0.001469</td>\n",
       "      <td>0.009776</td>\n",
       "      <td>0.084040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015963</td>\n",
       "      <td>0.020358</td>\n",
       "      <td>0.021270</td>\n",
       "      <td>0.074536</td>\n",
       "      <td>0.400537</td>\n",
       "      <td>0.070094</td>\n",
       "      <td>0.008211</td>\n",
       "      <td>0.389030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029268</td>\n",
       "      <td>0.099368</td>\n",
       "      <td>0.124170</td>\n",
       "      <td>0.472352</td>\n",
       "      <td>0.050068</td>\n",
       "      <td>0.046655</td>\n",
       "      <td>0.134861</td>\n",
       "      <td>0.043257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003487</td>\n",
       "      <td>0.013007</td>\n",
       "      <td>0.051353</td>\n",
       "      <td>0.062040</td>\n",
       "      <td>0.110950</td>\n",
       "      <td>0.011327</td>\n",
       "      <td>0.044089</td>\n",
       "      <td>0.703746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>0.155922</td>\n",
       "      <td>0.064877</td>\n",
       "      <td>0.325337</td>\n",
       "      <td>0.154746</td>\n",
       "      <td>0.074144</td>\n",
       "      <td>0.019239</td>\n",
       "      <td>0.064866</td>\n",
       "      <td>0.140869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>0.244311</td>\n",
       "      <td>0.028819</td>\n",
       "      <td>0.042939</td>\n",
       "      <td>0.444826</td>\n",
       "      <td>0.133845</td>\n",
       "      <td>0.029999</td>\n",
       "      <td>0.044792</td>\n",
       "      <td>0.030468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>0.353970</td>\n",
       "      <td>0.030451</td>\n",
       "      <td>0.144310</td>\n",
       "      <td>0.140590</td>\n",
       "      <td>0.249777</td>\n",
       "      <td>0.003942</td>\n",
       "      <td>0.032371</td>\n",
       "      <td>0.044589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>0.135979</td>\n",
       "      <td>0.014842</td>\n",
       "      <td>0.078236</td>\n",
       "      <td>0.330012</td>\n",
       "      <td>0.065415</td>\n",
       "      <td>0.016067</td>\n",
       "      <td>0.330583</td>\n",
       "      <td>0.028867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>0.007310</td>\n",
       "      <td>0.083441</td>\n",
       "      <td>0.096717</td>\n",
       "      <td>0.054286</td>\n",
       "      <td>0.079745</td>\n",
       "      <td>0.116096</td>\n",
       "      <td>0.093645</td>\n",
       "      <td>0.468759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>974 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Impressionist  Highly_Detailed  Human_Subject  Landscape  Abstract  \\\n",
       "0         0.035234         0.003798       0.022408   0.091478  0.716316   \n",
       "1         0.209611         0.019976       0.252444   0.410513  0.012170   \n",
       "2         0.015963         0.020358       0.021270   0.074536  0.400537   \n",
       "3         0.029268         0.099368       0.124170   0.472352  0.050068   \n",
       "4         0.003487         0.013007       0.051353   0.062040  0.110950   \n",
       "..             ...              ...            ...        ...       ...   \n",
       "969       0.155922         0.064877       0.325337   0.154746  0.074144   \n",
       "970       0.244311         0.028819       0.042939   0.444826  0.133845   \n",
       "971       0.353970         0.030451       0.144310   0.140590  0.249777   \n",
       "972       0.135979         0.014842       0.078236   0.330012  0.065415   \n",
       "973       0.007310         0.083441       0.096717   0.054286  0.079745   \n",
       "\n",
       "     Ornamental_Pattern  Animal_Subject  Architecture_Subject  \n",
       "0              0.005974        0.004790              0.120002  \n",
       "1              0.001469        0.009776              0.084040  \n",
       "2              0.070094        0.008211              0.389030  \n",
       "3              0.046655        0.134861              0.043257  \n",
       "4              0.011327        0.044089              0.703746  \n",
       "..                  ...             ...                   ...  \n",
       "969            0.019239        0.064866              0.140869  \n",
       "970            0.029999        0.044792              0.030468  \n",
       "971            0.003942        0.032371              0.044589  \n",
       "972            0.016067        0.330583              0.028867  \n",
       "973            0.116096        0.093645              0.468759  \n",
       "\n",
       "[974 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial['benchmark']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f38c585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Lifespan</th>\n",
       "      <th>Image_URL</th>\n",
       "      <th>Image_path</th>\n",
       "      <th>Birth</th>\n",
       "      <th>Death</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Construction</td>\n",
       "      <td>László Moholy-Nagy</td>\n",
       "      <td>Hungarian</td>\n",
       "      <td>1895 - 1946</td>\n",
       "      <td>https://raw.githubusercontent.com/Corriande/al...</td>\n",
       "      <td>Construction (1924).jpg</td>\n",
       "      <td>1895</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1924.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ohne Titel; aus; ‘Die 150 Blätter’ VII</td>\n",
       "      <td>Karl Wiener</td>\n",
       "      <td>Austrian</td>\n",
       "      <td>1901-1949</td>\n",
       "      <td>https://raw.githubusercontent.com/Corriande/al...</td>\n",
       "      <td>Ohne Titel; aus; ‘Die 150 Blätter’ VII (1940).jpg</td>\n",
       "      <td>1901</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>1940.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zeilboten op een werfhelling</td>\n",
       "      <td>Reijer Stolk</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>1896 - 1945</td>\n",
       "      <td>https://raw.githubusercontent.com/Corriande/al...</td>\n",
       "      <td>Zeilboten op een werfhelling (1906).jpg</td>\n",
       "      <td>1896</td>\n",
       "      <td>1945.0</td>\n",
       "      <td>1906.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why</td>\n",
       "      <td>Karl Wiener</td>\n",
       "      <td>Austrian</td>\n",
       "      <td>1901-1949</td>\n",
       "      <td>https://raw.githubusercontent.com/Corriande/al...</td>\n",
       "      <td>Why (1940).jpg</td>\n",
       "      <td>1901</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>1940.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Machinery</td>\n",
       "      <td>Charles Demuth</td>\n",
       "      <td>American</td>\n",
       "      <td>1883-1935</td>\n",
       "      <td>https://raw.githubusercontent.com/Corriande/al...</td>\n",
       "      <td>Machinery (1920).jpg</td>\n",
       "      <td>1883</td>\n",
       "      <td>1935.0</td>\n",
       "      <td>1920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>Periphery</td>\n",
       "      <td>Mikuláš Galanda</td>\n",
       "      <td>Slovak</td>\n",
       "      <td>1895 – 1938</td>\n",
       "      <td>https://raw.githubusercontent.com/Corriande/al...</td>\n",
       "      <td>Periphery (1924).jpg</td>\n",
       "      <td>1895</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>1924.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>Váza s kyticí a broskve (Vase of flowers and p...</td>\n",
       "      <td>Emil Filla</td>\n",
       "      <td>Czech</td>\n",
       "      <td>1882-1953</td>\n",
       "      <td>https://raw.githubusercontent.com/Corriande/al...</td>\n",
       "      <td>Váza s kyticí a broskve (Vase of flowers and p...</td>\n",
       "      <td>1882</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>1932.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>Self-Portrait</td>\n",
       "      <td>Ernst Ludwig Kirchner</td>\n",
       "      <td>German</td>\n",
       "      <td>1880-1938</td>\n",
       "      <td>https://raw.githubusercontent.com/Corriande/al...</td>\n",
       "      <td>Self-Portrait (1928).jpg</td>\n",
       "      <td>1880</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>1928.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>Klänge Pl.13</td>\n",
       "      <td>Wassily Kandinsky</td>\n",
       "      <td>Russian</td>\n",
       "      <td>1866 - 1944</td>\n",
       "      <td>https://raw.githubusercontent.com/Corriande/al...</td>\n",
       "      <td>Klänge Pl.13 (1913).jpg</td>\n",
       "      <td>1866</td>\n",
       "      <td>1944.0</td>\n",
       "      <td>1913.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>Beethovenfries; ‘Die Sehnsucht nach Glück find...</td>\n",
       "      <td>Gustav Klimt</td>\n",
       "      <td>Austrian</td>\n",
       "      <td>1862-1918</td>\n",
       "      <td>https://raw.githubusercontent.com/Corriande/al...</td>\n",
       "      <td>Beethovenfries; ‘Die Sehnsucht nach Glück find...</td>\n",
       "      <td>1862</td>\n",
       "      <td>1918.0</td>\n",
       "      <td>1901.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>974 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title                 Artist  \\\n",
       "0                                         Construction     László Moholy-Nagy   \n",
       "1               Ohne Titel; aus; ‘Die 150 Blätter’ VII            Karl Wiener   \n",
       "2                         Zeilboten op een werfhelling           Reijer Stolk   \n",
       "3                                                  Why            Karl Wiener   \n",
       "4                                            Machinery         Charles Demuth   \n",
       "..                                                 ...                    ...   \n",
       "969                                          Periphery        Mikuláš Galanda   \n",
       "970  Váza s kyticí a broskve (Vase of flowers and p...             Emil Filla   \n",
       "971                                      Self-Portrait  Ernst Ludwig Kirchner   \n",
       "972                                       Klänge Pl.13      Wassily Kandinsky   \n",
       "973  Beethovenfries; ‘Die Sehnsucht nach Glück find...           Gustav Klimt   \n",
       "\n",
       "    Nationality      Lifespan  \\\n",
       "0     Hungarian   1895 - 1946   \n",
       "1      Austrian     1901-1949   \n",
       "2         Dutch   1896 - 1945   \n",
       "3      Austrian     1901-1949   \n",
       "4      American     1883-1935   \n",
       "..          ...           ...   \n",
       "969      Slovak   1895 – 1938   \n",
       "970       Czech     1882-1953   \n",
       "971      German     1880-1938   \n",
       "972     Russian   1866 - 1944   \n",
       "973    Austrian     1862-1918   \n",
       "\n",
       "                                             Image_URL  \\\n",
       "0    https://raw.githubusercontent.com/Corriande/al...   \n",
       "1    https://raw.githubusercontent.com/Corriande/al...   \n",
       "2    https://raw.githubusercontent.com/Corriande/al...   \n",
       "3    https://raw.githubusercontent.com/Corriande/al...   \n",
       "4    https://raw.githubusercontent.com/Corriande/al...   \n",
       "..                                                 ...   \n",
       "969  https://raw.githubusercontent.com/Corriande/al...   \n",
       "970  https://raw.githubusercontent.com/Corriande/al...   \n",
       "971  https://raw.githubusercontent.com/Corriande/al...   \n",
       "972  https://raw.githubusercontent.com/Corriande/al...   \n",
       "973  https://raw.githubusercontent.com/Corriande/al...   \n",
       "\n",
       "                                            Image_path  Birth   Death    Year  \n",
       "0                              Construction (1924).jpg   1895  1946.0  1924.0  \n",
       "1    Ohne Titel; aus; ‘Die 150 Blätter’ VII (1940).jpg   1901  1949.0  1940.0  \n",
       "2              Zeilboten op een werfhelling (1906).jpg   1896  1945.0  1906.0  \n",
       "3                                       Why (1940).jpg   1901  1949.0  1940.0  \n",
       "4                                 Machinery (1920).jpg   1883  1935.0  1920.0  \n",
       "..                                                 ...    ...     ...     ...  \n",
       "969                               Periphery (1924).jpg   1895  1938.0  1924.0  \n",
       "970  Váza s kyticí a broskve (Vase of flowers and p...   1882  1953.0  1932.0  \n",
       "971                           Self-Portrait (1928).jpg   1880  1938.0  1928.0  \n",
       "972                            Klänge Pl.13 (1913).jpg   1866  1944.0  1913.0  \n",
       "973  Beethovenfries; ‘Die Sehnsucht nach Glück find...   1862  1918.0  1901.0  \n",
       "\n",
       "[974 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modern_gallery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f67accef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_clips_gallery(qualities, df):\n",
    "    \n",
    "    \n",
    "    \n",
    "    new_df = df.copy()\n",
    "    \n",
    "    # Create new columns in the DataFrame for each quality\n",
    "    for quality in qualities:\n",
    "        new_df[quality] = pd.NA  # Initialize with NA\n",
    "        \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Loop through each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        image_url = row['Image_URL']\n",
    "        try:\n",
    "            response = requests.get(image_url)\n",
    "            image = Image.open(BytesIO(response.content))\n",
    "            image.seek(0)  # Check if the image is valid and not corrupted\n",
    "\n",
    "            # Process the image and text prompts\n",
    "            inputs = processor(text=qualities, images=image, return_tensors=\"pt\", padding=True)\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "            # Get the logits from the model\n",
    "            with torch.no_grad():\n",
    "                logits_per_image = model(**inputs).logits_per_image\n",
    "                probs = logits_per_image.softmax(dim=-1)\n",
    "\n",
    "            # Store the results in the DataFrame\n",
    "            for i, quality in enumerate(qualities):\n",
    "                new_df.at[index, quality] = probs[0][i].item()\n",
    "\n",
    "        except (requests.exceptions.RequestException, UnidentifiedImageError, IOError):\n",
    "            # If the image can't be loaded or verified, leave the qualities as NA\n",
    "            print(f\"Image at {image_url} is not integral or couldn't be loaded.\")\n",
    "            # Optionally, log this issue or handle it as needed\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da5cdcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_contrast_qualities = [\n",
    "    \n",
    "    'Highly_Detailed',\n",
    "    'Impressionist',\n",
    "    'Human_Subject',\n",
    "    'Landscape',\n",
    "    'Abstract',\n",
    "    'Ornamental_Pattern',\n",
    "    'Animal_Subject',\n",
    "    'Architecture_Subject',\n",
    "    'Color_Contrast'\n",
    "    \n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf46d264",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_contrast_gallery = generate_clips_gallery(color_contrast_qualities, modern_gallery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0d4197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_contrast_gallery.to_csv(\"color_contrast_gallery.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2b5667d",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_gallery = generate_clips_gallery(strong_qualities, modern_gallery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8ac76745",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_gallery.to_csv(\"algo_gallery.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "136f0acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_gallery = generate_clips_gallery(strong_qualities, modern_gallery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1226e809",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_gallery.to_csv(\"colors_gallery.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "27b548bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_impressionist = generate_clips_gallery(strong_qualities, modern_gallery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbe80ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_impressionist.to_csv(\"no_impressionist.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
